---
title: "R Notebook"
output: github_document 
---
Permet la connection avec github
```{r}
install.packages("gitcreds")
library(gitcreds)
```

Charger les données
```{r}
library(phyloseq)
library(ggplot2)
library(dplyr)
devtools::load_all(path="course-material-main/R")
```
Chargement des données 
```{r}
output_beta <- here::here("outputs", "beta_diversity")
if (!dir.exists(output_beta)) dir.create(output_beta, recursive = TRUE)
```


```{bash}
cp -R course-material-main/data/asv_table ./data/
```

```{r}

physeq <- readRDS(here::here("data",
                             "asv_table",
                             "phyloseq_object_alpha_beta_div.rds"))
```

Sous échantillonnage de chaque échantillon sans remplacement à une profondeur constante
Détermine combien de lectures nous avons par échantillon 
```{r}
rowSums(physeq@otu_table@.Data)
```
Permet d'examiner l'abondance des classements des lectures et de tracer les résultats 
```{r}
readsumsdf <- data.frame(nreads = sort(taxa_sums(physeq), decreasing = TRUE),
                        sorted = 1:ntaxa(physeq),
                        type = "OTUs")

tmp <- data.frame(nreads = sort(sample_sums(physeq), decreasing = TRUE), 
                  sorted = 1:nsamples(physeq),
                  type = "Samples")

readsumsdf <- rbind(readsumsdf, tmp)

head(readsumsdf)
```

```{r}
ggplot(readsumsdf, aes(x = sorted, y = nreads)) +
  geom_bar(stat = "identity") +
  ggtitle("Total number of reads") +
  scale_y_log10() +
  facet_wrap(~type, nrow = 1, scales = "free")
```
Nous allons maintenant transformer en somme d'échantillon égale (uniquement si le nombre de lectures n'est pas le même entre les échantillons) afin de nous assurer que l'effort d'échantillonnage est le même entre les échantillons.
```{r}
# set the seed for random sampling
# it allows reproductibility
set.seed(10000)

# minimum reads in a sample
min(rowSums(physeq@otu_table@.Data))
```
Le nombre minimum de lectures dans un échantillon est de 837. Faisons la randomisation à 800 lectures par échantillon afin d'appliquer le processus également dans l'échantillon ayant ce minimum de lectures.
```{r}
physeq_rar <- rarefy_even_depth(physeq, sample.size = 800)
rowSums(physeq_rar@otu_table@.Data) #how many reads per sample
```

```{r}
physeq
```

```{r}
physeq_rar
```

On effectue la transformation de rapport logarithmique centré
```{r}
 # we first replace the zeros using
 # the Count Zero Multiplicative approach
tmp <- zCompositions::cmultRepl(physeq@otu_table,
                                method = "CZM",
                                label = 0,
                                z.warning = 1)

# generate the centered log-ratio transformed. ASVs are in rows!!!!!
physeq_clr_asv <- apply(tmp, 1, function(x) log(x) - mean(log(x)))
```

```{r}
#create a new phyloseq object with CLR tranformed counts
physeq_clr <- physeq
otu_table(physeq_clr) <- otu_table(t(physeq_clr_asv),
                                   taxa_are_rows = FALSE)
data.frame(physeq_clr@otu_table@.Data[1:5, 1:10])
```
Permet de visualiser l'abondance relative des organismes à des rangs taxonomiques spécifiques. Les treemaps et les barplots empilés sont deux façons de procéder.
```{r}
physeq_phylum <- physeq_rar %>%
  tax_glom(taxrank = "Family") %>%                     # agglomerate at the Family level
  transform_sample_counts(function(x) {x/sum(x)} ) %>% # Transform to rel. abundance
  psmelt() %>%                                         # Melt to long format
  filter(Abundance > 0.02) %>%                         # Filter out low abundance taxa
  arrange(Family)                                      # Sort data frame alphabetically by phylum

head(physeq_phylum)
```
Regarder la composition de la méta communauté avec un treemap permet de détecter grossièrement si certains taxons ne devraient pas être présents (contaminants) et d'observer si les taxons dominants correspondent à l'habitat étudié.
Permet d'utiliser la package treemap
```{r}
#pdf(file="treemap.pdf", wi = 7, he = 7)

treemap::treemap(physeq_phylum, index=c("Class", "Family"), vSize="Abundance", type="index",
        fontsize.labels=c(15,12),                # size of labels. Give the size per level of aggregation: size for group, size for subgroup, sub-subgroups...
        fontcolor.labels=c("white","black"),    # Color of labels
        fontface.labels=c(2,1),                  # Font of labels: 1,2,3,4 for normal, bold, italic, bold-italic...
        align.labels=list(
          c("center", "center"), 
          c("left", "bottom")),                 # Where to place labels in the rectangle?
        overlap.labels=0.5,                      # number between 0 and 1 that determines the tolerance of the overlap between labels. 0 means that labels of lower levels are not printed if higher level labels overlap, 1  means that labels are always printed. In-between values, for instance the default value .5, means that lower level labels are printed if other labels do not overlap with more than .5  times their area size.
        inflate.labels=F, # If true, labels are bigger when rectangle is bigger.
        border.col=c("black","white"),          #Color of the boders separating the taxonomic levels
        border.lwds=c(4,2),
        #palette = "Set3",                        # Select your color palette from the RColorBrewer presets or make your own.
        fontsize.title=12
)
```

```{r}
#dev.off()
```

Permet d'utiliser le package treemapify
```{r}
tmp <- transform_sample_counts(physeq,function(x) {x/sum(x)} ) %>%
  psmelt() %>%
  group_by(Family, Class) %>%
  summarise(abundance = sum(Abundance)) %>%
  na.omit()

ggplot(tmp,aes(area=abundance,label=Family,fill=Class,subgroup=Class))+
  treemapify::geom_treemap()+
  treemapify::geom_treemap_subgroup_border() +
  treemapify::geom_treemap_subgroup_text(place = "centre",
                                         grow = T,
                                         alpha = 0.5,
                                         colour = "black",
                                         fontface = "italic",
                                         min.size = 0) +
  treemapify::geom_treemap_text(colour = "white",
                                place = "topleft",
                                reflow = TRUE)+
  theme(legend.position="none")
```

```{r}
ggsave(here::here(output_beta,"treemap_treemapify.pdf"))
```

Ici, nous pouvons observer que la méta-communauté est dominée par des clades marins typiques tels que le groupe marin AEGEAN des Alphaprotéobactéries ou le clade SAR86 des Gammaprotéobactéries. Donc tout va bien jusqu’à présent.
Permet de faire des barplots empilés
```{r}
ggplot(physeq_phylum, aes(x = Sample, y = Abundance, fill = Family)) + 
  geom_bar(stat = "identity") +
  # facet_wrap(~Treatment, nrow=1, scales = "free_x") +
  ylab("Relative Abundance (Family > 2%)") +
  scale_y_continuous(expand = c(0,0)) + #remove the space below the 0 of the y axis in the graph
  ggtitle("Community composition") +
  theme_bw() +
  theme(axis.title.x = element_blank(),
        axis.text.x = element_text(angle = 45, size = 10,
                                   hjust = 0.5, vjust = 0.8),
        axis.ticks.x = element_blank(),
        panel.background = element_blank(), 
        panel.grid.major = element_blank(),  #remove major-grid labels
        panel.grid.minor = element_blank())  #remove minor-grid labels
```

```{r}
ggsave(here::here(output_beta, "asv_composition.pdf"))
```
Ici on peut déjà constater quelques différences dans la composition au niveau de la Famille avec un enrichissement en Pseudoalteromonadaceae dans certains échantillons et en Cyanobiaceae. Notez que nous sommes limités par notre capacité à discerner plus de 9 à 12 couleurs dans ce type de graphique.

Permet de faire une matrice taxonomique compositionnelle 
```{r}
physeq_rar_jaccard <- phyloseq::distance(physeq_rar,
                                         method = "jaccard",
                                         binary = TRUE)

# trick to avoid negative egein values in PCoA
# it recreates what ade4::dist.binary() does
physeq_rar_jaccard <- sqrt(physeq_rar_jaccard)
```

Phylogénétique compositionnelle 
Le package GUniFrac nécessite une arborescence enracinée comme données d'entrée. Nous pouvons utiliser la fonction midpoint() du package phangorn pour obtenir l'arbre enraciné.
Pour vérifier si votre arbre est enraciné, vous pouvez utiliser cette fonction :
```{r}
ape::is.rooted(physeq_rar@phy_tree)
```

Sinon, vous pouvez utiliser la fonction midpoint() du package phancorn
```{r}
phy_tree(physeq_rar) <- phangorn::midpoint(physeq_rar@phy_tree)
```

Désormais, les distances Unifrac peuvent être calculées
```{r}
unifracs <- GUniFrac::GUniFrac(physeq_rar@otu_table@.Data, physeq_rar@phy_tree, alpha=c(0, 0.5, 1))$unifracs
```

L'objet unifracs est une liste contenant 5 matrices de distance correspondant à l'UniFrac pondéré (d_1), à l'UniFrac non pondéré (d_UW), à l'UniFrac ajusté à la variance (d_VAW), au GUniFrac avec alpha = 0, au GUniFrac avec alpha = 0,5.
```{r}
physeq_rar_du <- unifracs[, , "d_UW"]   # Unweighted UniFrac
```


Matrice taxonomique structurale (Bray-Curtis) :
```{r}
# physeq_rar_bray <- vegan::vegdist(physeq_rar@otu_table@.Data, method = "bray")

tmp <- transform_sample_counts(physeq,function(x) {x/sum(x)} )
physeq_rar_bray <- phyloseq::distance(tmp, method = "bray")
```

Matrice taxonomique structurale (UniFrac pondéré) : 
```{r}
physeq_rar_dw <- unifracs[, , "d_1"]   # Weighted UniFrac
```

 Ici, nous allons parcourir chaque méthode de distance, enregistrer chaque tracé dans une liste, puis tracer ces résultats dans un graphique combiné à l'aide de ggplot2.
```{r}
dist_methods <- unlist(distanceMethodList)
data.frame(position = seq_along(dist_methods),
           dist_methods)
```

```{r}
#Select the distances of interest
dist_methods <- dist_methods[c(1, 2, 10, 8)]
dist_methods
```

```{r}
#Loop through each distance method, save each plot to a list, called plist.
plist <- vector("list")

for(i in dist_methods){
  # Calculate distance matrix
  iDist <- phyloseq::distance(physeq_rar, method = i)
  # Calculate PCoA ordination
  iMDS <- ordinate(physeq_rar, "MDS", distance = iDist)
  ## Make plot. Don't carry over previous plot (if error, p will be blank)
  p <- NULL
  # Create plot, store as temp variable, p
  p <- plot_ordination(physeq_rar, iMDS, color= "Geo")
  # Add title to each plot
  p <- p + ggtitle(paste("MDS using distance method ", i, sep=""))
  # Save the graphic to list
  plist[[i]] = p 
}
```

Combiner les résultats
```{r}
df <- plyr::ldply(plist, function(x) x$data)
head(df)
```

```{r}
names(df)[1] <- "distance"

ggplot(df, aes(Axis.1, Axis.2, color = Geo)) +
  geom_point(size=3, alpha=0.5) +
  theme_bw() +
  facet_wrap(~distance, scales="free") +
  ggtitle("PCoA (MDS) on various distance metrics")
```
On peut observer qu'il y a une assez bonne séparation entre les échantillons Nord et Sud à l'exception de la distance Weighted UniFrac qui a tendance à donner trop de poids aux ASV les plus abondants mais aussi les plus fréquents.

Permet de faire une classification ascendante hiérarchique : 
Une première étape dans de nombreux projets sur le microbiome consiste à examiner comment les échantillons se regroupent selon une certaine mesure de (dis)similitude. Il existe de nombreuses façons d'effectuer un tel clustering. 
Étant donné que les données du microbiome sont compositionnelles, nous effectuerons ici une classification hiérarchique ascendante (HAC) des échantillons basée sur la distance d'Aitchison.

```{r}
#distance matrix calculation
physeq_clr_dist <- phyloseq::distance(physeq_clr, method = "euclidean")
```

Voyons les différents clusterings obtenus avec les quatre critères d'agrégation
```{r}
#Simple aggregation criterion
spe_single <- hclust(physeq_clr_dist, method = "single")

#Complete aggregation criterion
spe_complete <- hclust(physeq_clr_dist, method = "complete")

#Unweighted pair group method with arithmetic mean
spe_upgma <- hclust(physeq_clr_dist, method = "average")

#Ward criterion
spe_ward <- hclust(physeq_clr_dist, method = "ward.D")

par(mfrow = c(2, 2))
plot(spe_single, main = "single")
plot(spe_complete, main = "complete")
plot(spe_upgma, main = "UPGMA")
plot(spe_ward, main = "ward")
```
N'oubliez pas que le clustering est une procédure heuristique et non un test statistique. Les choix d'un coefficient d'association et d'une méthode de clustering influencent le résultat. Cela souligne l’importance de choisir une méthode cohérente avec les objectifs de l’analyse.

Corrélation cophénétique : 
Une matrice cophénétique est une matrice représentant les distances cophénétiques entre toutes les paires d'objets. Une corrélation r de Pearson, appelée corrélation cophénétique dans ce contexte, peut être calculée entre la matrice de dissimilarité originale et la matrice cophénétique. La méthode présentant la corrélation cophénétique la plus élevée peut être considérée comme celle qui a produit le meilleur modèle de regroupement pour la matrice de distance.

Calculons la matrice cophénétique et la corrélation des quatre résultats de clustering présentés ci-dessus, au moyen de la fonction cophenetic() du package stats.

```{r}
#Cophenetic correlation
spe_single_coph <- cophenetic(spe_single)
cor(physeq_clr_dist, spe_single_coph)
spe_complete_coph <- cophenetic(spe_complete)
cor(physeq_clr_dist, spe_complete_coph)
spe_upgma_coph <- cophenetic(spe_upgma)
cor(physeq_clr_dist, spe_upgma_coph)
spe_ward_coph <- cophenetic(spe_ward)
cor(physeq_clr_dist, spe_ward_coph)
```

Pour illustrer la relation entre une matrice de distance et un ensemble de matrices cophénétiques obtenues à partir de diverses méthodes, on peut dessiner des diagrammes de type Shepard en traçant les distances originales par rapport aux distances cophénétiques.

```{r}
plot_coph_cor <- function(cophenetic_distance, hclust_type){

  # first calculate the correlation between
  # the cophenetic distance and the observed distance
  cor_res <- round(cor(physeq_clr_dist, cophenetic_distance),3)

  # generate a scatter plot to visualise
  # the relationship
  plot(x = physeq_clr_dist,
     y = cophenetic_distance,
     xlab = "Aitchison distance",
     ylab = "Cophenetic distance",
     xlim = c(10, 35), ylim = c(10, 35),
     main = c(hclust_type, paste("Cophenetic correlation ", cor_res)))
  abline(0, 1)
}

par(mfrow=c(2,2))

plot_coph_cor(cophenetic_distance = spe_complete_coph,
              hclust_type = "Single linkage")

plot_coph_cor(cophenetic_distance = spe_complete_coph,
              hclust_type = "Complete linkage")

plot_coph_cor(cophenetic_distance = spe_upgma_coph,
              hclust_type = "Average linkage")

plot_coph_cor(cophenetic_distance = spe_ward_coph,
              hclust_type = "Ward linkage")
```
Il semble clair que la méthode UPGMA donne la représentation la plus fidèle des distances originales.

Recherche de clusters interprétables : 
Pour interpréter et comparer les résultats du clustering, les utilisateurs recherchent généralement des clusters interprétables. Cela signifie qu’une décision doit être prise : à quel niveau faut-il couper le dendrogramme ? De nombreux indices (plus de 30) ont été publiés dans la littérature pour trouver le bon nombre de clusters dans un ensemble de données. Les valeurs du niveau de fusion d'un dendrogramme sont les valeurs de dissimilarité où se produit une fusion entre deux branches d'un dendrogramme. Tracer les valeurs du niveau de fusion peut aider à définir les niveaux de coupe. Traçons les valeurs du niveau de fusion pour le dendrogramme UPGMA.

```{r}
#Fusion level plot
par(mfrow = c(1, 1))

plot(x = spe_upgma$height,
     y = phyloseq::nsamples(physeq_clr):2,
     type = "S",
     main = "Fusion levels - Aitchison - Average",
     ylab = "k (number of cluster)",
     xlab = "h (node height)")

text(x = spe_upgma$height,
     y = phyloseq::nsamples(physeq_clr):2,
     labels = phyloseq::nsamples(physeq_clr):2,
     col = "red",
     cex = 0.8)
```

De droite à gauche, ce premier graphique montre des sauts nets après chaque fusion entre 2 groupes. Nous utiliserons le package NbClust qui calculera, avec un seul appel de fonction, 24 indices pour confirmer le bon nombre de clusters dans l'ensemble de données :
```{r}
install.packages("NbClust", lib = ".")
library("NbClust", lib.loc = ".")
nclust <- nb_clust_all(data = t(physeq_clr_asv), seed = 1000)
```

NbClust confirme l'identification de deux groupes d'échantillons. Nous reviendrons sur le dendrogramme et le découperons aux distances correspondantes.

```{r}
#Cut the dendrogram in order to obtain K groups and compare their compositionC
k <- 2 # Number of groups given by the fusion level plot

#Cut the dendrogram
spe_upgma_clust <- cutree(tree = spe_upgma, k = k)
table(spe_upgma_clust)
```

```{r}
spe_upgma_clust2 <- data.frame(UPGMA_clusters = spe_upgma_clust)
```

```{r}
# Plot dendrogram with group labels
plot(spe_upgma,
     hang = -1,
     ylab = "Height",
     main="Aitchison distance - UPGMA")

rect.hclust(spe_upgma,
            k = k,
            border = 2:6,
            cluster = spe_upgma_clust)

legend("topright",
       paste("Cluster", 1:k),
       pch = 22,
       col = 2:(k + 1),
       bty = "n")
```

Il existe plusieurs façons de mesurer la robustesse d’un algorithme de clustering. Trois mesures couramment utilisées sont l'indice Dunn, l'indice Davis-Bouldin et l'indice Silhoutte.
Nous utiliserons la fonction cluster.stats() dans le package fpc pour calculer l'index Dunn qui peut être utilisé pour la validation du cluster : 

```{r}
cs <- fpc::cluster.stats(d = physeq_clr_dist,
                         clustering = spe_upgma_clust)

cs$dunn
```

L'indice de Dunn est élevé, ce qui indique un bon regroupement des échantillons. Maintenant que nous avons identifié deux groupes d’échantillons en fonction de la composition de leur communauté microbienne, nous souhaiterons peut-être examiner quels clades microbiens ou ASV sont enrichis dans chacun des groupes.


Combinaison du clustering et de la Heatmap Z-score : 

Les cartes thermiques du score Z sont normalisées (centrée autour de la moyenne (par ligne !!) et réduites (écart type = SD). C'est la comparaison d'une valeur observée d'un échantillon à la moyenne de la population. Elle répond donc à la question , à quelle distance de la moyenne de la population se trouve un score pour un échantillon donné. Les scores sont donnés en SD par rapport à la moyenne de la population.

Sélection des 30 meilleurs ASV :

```{r}
#Transform Row/normalized counts in percentage: transform_sample_counts
pourcentS <- phyloseq::transform_sample_counts(physeq_rar, function(x) x/sum(x) * 100)
#Selection of top 30 taxa 
mytop30 <- names(sort(phyloseq::taxa_sums(pourcentS), TRUE)[1:30])
#Extraction of taxa from the object pourcentS
selection30 <- phyloseq::prune_taxa(mytop30, pourcentS)
#See new object with only the top 30 ASV
selection30
```

Permet d'obtenir la transformation otu_table et Z-score

```{r}
#Retrieve abundance of ASV (otu_table) as table & put in data.prop variable
selection30_asv <- phyloseq::otu_table(selection30)
selection30_sample <- phyloseq::sample_data(selection30)

#Change the rownames
#See
rownames(selection30_asv)
```

```{r}
#Change... Why?

# rownames(data.prop)<-c("S11B_South5B","S1B_North1B","S2B_North2B","S2S_North2S","S3B_North3B","S3S_North3S","S4B_North4B","S4S_North4S","S5B_North5B","S5S_North5S","S6B_South1B","S6S_South1S","S7B_South2B","S7S_South2S","S8B_South3B","S8S_South3S","S9B_South4B","S9S_South4S")

sample_new_names <- paste(selection30_sample$SampName,
                          selection30_sample$Description,
                          sep = "_")

#Z-score transformation (with scale)
heat <- t(base::scale(selection30_asv))
#See
head(data.frame(heat))
```


Score Z de la carte thermique : 
```{r}
ComplexHeatmap::Heatmap(
  heat,
  row_names_gp = grid::gpar(fontsize = 6),
  cluster_columns = FALSE,
  heatmap_legend_param = list(direction = "vertical",
                              title = "Z-scores", 
                              grid_width = unit(0.5, "cm"),
                              legend_height = unit(3, "cm"))
)
```


Ajouter la taxonomie pour les noms ASV : 
```{r}
#get taxnomic table
taxon <- phyloseq::tax_table(selection30) |>
  as.data.frame()

#concatene ASV with Phylum & Family names
myname <- paste(rownames(taxon), taxon$Phylum, taxon$Family, sep="_")
#apply
colnames(selection30_asv) <- myname
```

Appliquer à la heatmap : 
```{r}
#re-run Z-score to take into account the colnames change
heat <- t(scale(selection30_asv))

my_top_annotation <- ComplexHeatmap::anno_block(gp = grid::gpar(fill =c(3,4)),
                                               labels = c(1, 2),
                                               labels_gp = grid::gpar(col = "white",
                                                                      fontsize = 10))

ComplexHeatmap::Heatmap(
  heat,
  row_names_gp = grid::gpar(fontsize = 6),
  cluster_columns =TRUE,
  heatmap_legend_param = list(direction = "vertical",
   title ="Z-scores",
   grid_width = unit(0.5, "cm"),
   legend_height = unit(4, "cm")),
  top_annotation = ComplexHeatmap::HeatmapAnnotation(foo = my_top_annotation),
  column_km = 2,
  column_names_gp= grid::gpar(fontsize = 6)
  )
```

Ajouter un boxplot de la distribution de l'abondance de l'ASV dans l'échantillon :
```{r}
boxplot <- ComplexHeatmap::anno_boxplot(t(selection30_asv), 
                                        which = "row",
                                        gp = grid::gpar(fill = "turquoise3"))

my_boxplot_left_anno <- ComplexHeatmap::HeatmapAnnotation(Abund = boxplot,
                                                          which = "row",
                                                          width = unit(3, "cm"))

my_top_anno <- ComplexHeatmap::anno_block(gp = grid::gpar(fill = c(3, 6)),
                                          labels = c("South", "North"),
                                          labels_gp = grid::gpar(col = "white",
                                                                fontsize = 10))

my_top_anno <- ComplexHeatmap::HeatmapAnnotation(foo = my_top_anno)

ComplexHeatmap::Heatmap(
  heat,
  row_names_gp = grid::gpar(fontsize = 7),
  left_annotation = my_boxplot_left_anno, 
  heatmap_legend_param = list(direction = "vertical",
                              title ="Z-scores",
                              grid_width = unit(0.5, "cm"),
                              legend_height = unit(3, "cm")),
  top_annotation = my_top_anno,
  column_km = 2,
  cluster_columns = TRUE,
  column_dend_side = "bottom",
  column_names_gp = grid::gpar(fontsize = 7)
  )
```

Nous pouvons maintenant observer que les communautés microbiennes des échantillons du sud diffèrent dans leur composition microbienne de celles des échantillons du nord. L'effet significatif du traitement (Nord/Sud) reste à tester statistiquement, nous verrons comment cela se fait dans la section test des hypothèses. Cette différence dans la composition de la communauté est due à l’abondance différentielle apparente de nombreux ASV principaux de l’ensemble de données. L’identification de biomarqueurs significatifs dans les échantillons du Nord et du Sud sera abordée dans la section sur les tests d’abondance différentielle.

Analyse de gradient indirect : 

Analyse en composantes principales (ACP) : 
L'analyse en composantes principales (ACP) est une méthode permettant de résumer, dans un espace de faible dimension, la variance dans une dispersion multivariée de points.

Nombre de PC à conserver : 
Tout d’abord, nous utiliserons un graphique d’éboulis pour examiner la proportion de variation totale expliquée par chaque PC : 

```{r}
#prepare the ASV table to add taxonomy
tax_CLR <-  as.data.frame(tax_table(physeq_clr)) # get taxnomic table
#concatene ASV with Family & Genus names
ASVname <- paste(rownames(tax_CLR), tax_CLR$Family, tax_CLR$Genus,sep="_")
#apply 
rownames(physeq_clr_asv) <- ASVname
p <- PCAtools::pca(physeq_clr_asv,
                   metadata = data.frame(sample_data(physeq_clr)))
PCAtools::screeplot(p, axisLabSize = 18, titleLabSize = 22)
```

```{r}
#variance explained by each PC
```

On voit ici que le premier PC se démarque vraiment avec 31% de variance expliquée puis on a une diminution progressive pour les composantes restantes. Un tracé d'éboulis à lui seul montre simplement la proportion cumulative de variation expliquée, mais nous voulons déterminer le nombre optimal de PC à conserver.


```{r}
#Horn’s parallel analysis (Horn 1965) (Buja and Eyuboglu 1992)
horn <- PCAtools::parallelPCA(physeq_clr_asv)
horn$n
```

```{r}
#elbow method
elbow <- PCAtools::findElbowPoint(p$variance)
elbow
```

Les deux méthodes indiquent qu'il faut retenir les 2 ou 3 premiers PC. La raison de cet écart est que trouver le nombre correct de PC est une tâche difficile et revient à trouver le nombre « correct » de clusters dans un ensemble de données : il n’y a pas de bonne réponse. La plupart des études ne prennent en compte que les deux premiers PC.

Permet de tracer l'ordination :
```{r}
#Plotting the PCA
PCAtools::biplot(
  p,
  lab = p$metadata$SampName,
  colby = "Geo",
  pointSize = 5,
  hline = 0, vline = 0,
  legendPosition = "right"
)
```

Chaque point est un échantillon, et les échantillons qui semblent plus rapprochés sont généralement plus similaires les uns aux autres que les échantillons plus éloignés. Ainsi en colorant les points par traitement on constate que les microbiotes du Nord sont souvent, mais pas toujours, très distincts des échantillons du Sud.



Permet de déterminer les variables qui déterminent la variation entre chaque PC : 

L’un des avantages de ne pas utiliser de matrice de distance est que vous pouvez tracer les « chargements » de taxons sur vos axes PCA, en utilisant l’ argument showLoadings = TRUE . PCAtools vous permet de tracer le nombre de vecteurs de chargement de taxons souhaités en commençant par ceux ayant le plus de poids sur chaque PC. La longueur relative de chaque vecteur de chargement indique sa contribution à chaque axe PCA affiché et vous permet d'estimer approximativement quels échantillons contiendront le plus de ce taxon.
```{r}
PCAtools::biplot(
  p, 
  # loadings parameters
  showLoadings = TRUE,
  lengthLoadingsArrowsFactor = 1.5,
  sizeLoadingsNames = 3,
  colLoadingsNames = 'red4',
  ntopLoadings = 3,
  # other parameters
  lab = p$metadata$X.SampleID,
  colby = "Geo",
  hline = 0, vline = 0,
  legendPosition = "right"
)
```
Les ASV 7, 11 et 12 ont une contribution élevée au PC1 tandis que les ASV 38, 40 et 47 ont une contribution élevée au deuxième PC. Ces ASV appartiennent à seulement deux familles. Les échantillons du Sud semblent être enrichis en ASV7 tandis que les échantillons du Nord contiennent des abondances plus élevées d'ASV11 et 12. Les deux valeurs aberrantes de l'échantillon du Nord en haut du graphique sont caractérisées par une abondance plus élevée d'ASV 38, 40 et 47.

Corréler les principales composantes avec les données environnementales : 
Une exploration plus approfondie des PC peut passer par des corrélations avec des données environnementales. Ici, nous allons corréler les deux premiers PC avec des données environnementales.

```{r}
PCAtools::eigencorplot(
  p,
  components = PCAtools::getComponents(p, 1:horn$n),
  metavars = c('SiOH4','NO2','NO3','NH4','PO4',
              'NT','PT','Chla',"T", "S", "Sigma_t"),
  col = c('white', 'cornsilk1', 'gold',
          'forestgreen', 'darkgreen'),
  cexCorval = 1.2,
  fontCorval = 2,
  posLab = "all",
  rotLabX = 45,
  scale = TRUE,
  main = bquote(PC ~ Spearman ~ r^2 ~ environmental ~ correlates),
  plotRsquared = TRUE,
  corFUN = "spearman",
  corUSE = "pairwise.complete.obs",
  corMultipleTestCorrection = 'BH',
  signifSymbols = c("****", "***", "**", "*", ""),
  signifCutpoints = c(0, 0.0001, 0.001, 0.01, 0.05, 1)
)
```
La seule corrélation significative trouvée se situe entre le premier PC1 expliquant la séparation entre les échantillons Sud et Nord et la salinité. Ceci n'est pas intéressant mais la corrélation entre les variables ne signifie pas automatiquement que le changement d'une variable est la cause du changement des valeurs de l'autre variable. Nous vérifierons plus tard s'il existe une relation causale entre le gradient de salinité et la différence observée dans les communautés bactériennes du sud et du nord.

Analyse en composantes principales (PCoA): 
L'analyse des coordonnées principales tente de représenter les distances entre les échantillons dans un espace euclidien de faible dimension. En particulier, il maximise la corrélation linéaire entre les distances dans la matrice de distance et les distances dans un espace de faible dimension. Comme toujours, le choix de la mesure de (dis)similarité est critique et doit être adapté aux données en question. Ici, nous utiliserons la distance Bray-Curtis. Lorsque la métrique de distance est euclidienne, PCoA équivaut à l’analyse en composantes principales. L'interprétation des résultats est la même qu'avec l'ACP.

```{r}
#BPCoA on Bray-Curtis dissimilarity
pcoa_asv <- ape::pcoa(physeq_rar_bray)
pcoa_coord <- pcoa_asv$vectors[, 1:2]

#Data frame for hull
hull <- data.frame("Axis.1" = pcoa_coord[, 1],
                   "Axis.2" = pcoa_coord[, 2],
                   "sample" = as.data.frame(sample_data(physeq_rar@sam_data)))


# North <- hull[hull$sample.Geo  == "North", ][chull(hull[hull$sample.Geo ==  "North", c("Axis.1", "Axis.2")]), ]  # hull values for North
# South <- hull[hull$sample.Geo == "South", ][chull(hull[hull$sample.Geo == 
#                                                          "South", c("Axis.1", "Axis.2")]), ]  # hull values for Jellyfishes  

# hull_data <- rbind(North, South)

#Vector of color for hulls
# color <- rep("#a65628", length(hull_data$sample.Geo))
# color[hull_data$sample.Geo == "North"] <- "#1919ff"
# hull_data <- cbind(hull_data, color)

hull_col <- c("#a65628","#1919ff")
names(hull_col) <- c("North","South")

hull_data <- hull %>%
  dplyr::group_by(sample.Geo) %>%
  dplyr::slice(chull(Axis.1,Axis.2)) %>%
  dplyr::mutate(color = hull_col[sample.Geo])

head(hull_data)
```

Maintenant que nous avons préparé les données, traçons le PCoA.
```{r}
ggplot(data = hull, aes(x = Axis.1, y = Axis.2)) +
  geom_hline(yintercept = 0, colour = "lightgrey", linetype = 2) +
  geom_vline(xintercept = 0, colour = "lightgrey", linetype = 2) +
  geom_polygon(data = hull_data,
               aes(group = sample.Geo,
                   fill = sample.Geo),
               alpha = 0.3) + # add the convex hulls)
  scale_fill_manual(values = c("Darkgrey", "#1919ff")) +
  geom_point(data = hull,
             aes(color = sample.Geo,
                 size = sample.S),
             alpha = 0.7) +
  scale_color_manual(values = c("Darkgrey", "#1919ff")) +
  xlab(paste("PCo1 (", round(pcoa_asv$values$Relative_eig[1]*100, 1), "%)")) +
  ylab(paste("PCo2 (", round(pcoa_asv$values$Relative_eig[2]*100, 1), "%)")) +
  theme_bw() +
  coord_equal() +
  theme(axis.title.x = element_text(size = 14), # remove x-axis labels
        axis.title.y = element_text(size = 14), # remove y-axis labels
        panel.background = element_blank(), 
        panel.grid.major = element_blank(),  #remove major-grid labels
        panel.grid.minor = element_blank(),  #remove minor-grid labels
        plot.background = element_blank())
```

L’ordination des échantillons dans la PCoA est très similaire à celle observée dans la PCA avec une nette ségrégation des communautés bactériennes Nord et Sud. Cette ségrégation pourrait résulter de l'augmentation du gradient de salinité du Nord vers le Sud mais reste à tester.

En effet, aucune espèce n'est tracée sur cette ordination. C'est parce que nous avons utilisé une matrice de dissimilarité (sites x sites) comme entrée pour la fonction PCoA. Par conséquent, aucun score d’espèce n’a pu être calculé. Cependant, nous pourrions contourner ce problème avec la fonction biplot.pcoa()du apepackage.

PCoA souffre d'un certain nombre de défauts, notamment l'effet arch (voir PCA pour plus d'informations). Ces défauts proviennent en partie du fait que la PCoA maximise une corrélation linéaire. La mise à l'échelle multidimensionnelle non métrique (NMDS) corrige ce problème en maximisant la corrélation de l'ordre de classement.


Mise à l'échelle multidemensionnelle non métrique (NMDS):
NMDS est une approche basée sur le classement.

Les axes ne sont pas commandés dans NMDS. vegan::metaMDS()fait automatiquement pivoter le résultat final du NMDS à l'aide de la PCA pour que l'axe 1 corresponde à la plus grande variance parmi les points d'échantillonnage du NMDS.
```{r}
#NMDS plot on Aitchison distance
physeq_clr_nmds <- vegan::metaMDS(physeq_clr_dist, k=2, trymax=100) #Aitchison distance
```


Un moyen utile d'évaluer la pertinence d'un résultat NMDS consiste à comparer, dans un diagramme de Shepard, les distances entre les objets du tracé d'ordination avec les distances d'origine.

```{r}
vegan::stressplot(physeq_clr_nmds)
```

Il existe un bon ajustement non métrique entre les dissimilarités observées (dans notre matrice de distance) et les distances dans l'espace d'ordination. De plus, le stress de notre résultat final était bon.

Nous pouvons donc aller plus loin et tracer les résultats :
```{r}
nmds_coord <- data.frame(physeq_clr_nmds$points)

#Data frame for hull
hull <- data.frame("Axis.1" = nmds_coord[,1],
                   "Axis.2" = nmds_coord[,2],
                   "sample" = as.data.frame(sample_data(physeq_clr@sam_data)))

# North <- hull[hull$sample.Geo  == "North", ][chull(hull[hull$sample.Geo == 
#                                                                 "North", c("Axis.1", "Axis.2")]), ]  # hull values for North
# South <- hull[hull$sample.Geo == "South", ][chull(hull[hull$sample.Geo == 
#                                                                "South", c("Axis.1", "Axis.2")]), ]  # hull values for Jellyfishes  

# hull_data <- rbind(North, South)

# #Vector of color for hulls
# color <- rep("#a65628", length(hull_data$sample.Geo))
# color[hull_data$sample.Geo == "North"] <- "#1919ff"
# hull_data <- cbind(hull_data, color)

hull_col <- c("#a65628","#1919ff")
names(hull_col) <- c("North","South")

hull_data <- hull %>%
  dplyr::group_by(sample.Geo) %>%
  dplyr::slice(chull(Axis.1,Axis.2)) %>%
  dplyr::mutate(color = hull_col[sample.Geo])

#pdf(file="NMDS_Aitchison.pdf", wi = 7, he = 7)
ggplot(hull,aes(x = Axis.1, y = Axis.2)) +
  geom_hline(yintercept = 0, colour = "lightgrey", linetype = 2) + 
  geom_vline(xintercept = 0, colour = "lightgrey", linetype = 2) +
  geom_polygon(data = hull_data,
               aes(group = sample.Geo,
                   fill = sample.Geo),
               alpha = 0.3) + # add the convex hulls)
  scale_fill_manual(values = c("Darkgrey", "#1919ff")) +
  geom_point(data = hull,
             aes(color = sample.Geo,
                 size = sample.S),
             alpha = 0.7) +
  scale_color_manual(values = c("Darkgrey", "#1919ff")) +
  geom_text(data = hull_data,
            x = -0, y = -9,
            label = paste("Stress =", round(physeq_clr_nmds$stress, 2)),
            colour = "Black",
            size = 5)  +
  xlab(paste("MDS1")) +
  ylab(paste("MDS2")) +
  theme_bw() +
  coord_equal() +
  theme(axis.title.x = element_text(size=14), # remove x-axis labels
        axis.title.y = element_text(size=14), # remove y-axis labels
        panel.background = element_blank(), 
        panel.grid.major = element_blank(),  #remove major-grid labels
        panel.grid.minor = element_blank(),  #remove minor-grid labels
        plot.background = element_blank())
```

```{r}
#dev.off()
```

Nous observons le même modèle d’ordonnancement des échantillons que dans le PCA et le PCoA. Il n’y a pas de scores d’espèces (même problème que celui rencontré avec PCoA). Nous pouvons contourner ce problème en utilisant la fonction wascores en donnant à metaMDS la matrice de communauté d'origine en entrée et en spécifiant la mesure de distance.

La question suivante est la suivante : quelle variable environnementale est à l’origine des différences observées dans la composition des espèces ? De la même manière que nous l’avons fait avec PCA, nous pouvons corréler les variables environnementales avec nos axes d’ordination.

```{r}
# Correlation with environmental data
data.frame(names(hull))
```

```{r}
env <- hull[, 13:23]

# The function envfit will add the environmental variables as vectors to the ordination plot
ef <- vegan::envfit(physeq_clr_nmds, env, permu = 1000)
ef
```

```{r}
# The two last columns are of interest: the squared correlation coefficient and the associated p-value
# Plot the vectors of the significant correlations and interpret the plot
plot(physeq_clr_nmds, type = "t", display = "sites")
plot(ef, p.max = 0.05)
```

Là encore, on constate que la salinité est fortement corrélée au premier axe séparant les échantillons du Sud et du Nord. Dans une moindre mesure, de nouvelles variables environnementales liées aux conditions trophiques de l'habitat (NH4 et PT) ont été corrélées au deuxième axe du NMDS. La détection de ces nouvelles relations entre les communautés microbiennes et l'environnement peut être liée au fait que le NMDS est le mieux adapté pour détecter la réponse non linéaire des microbes aux gradients environnementaux.


Analyses de tests d'hypothèses : 

Analyse multiple permutationnelle de la variance (PERMANOVA) : 

Évaluons maintenant si le groupe (Nord vs Sud) a un effet significatif sur la composition globale de la communauté bactérienne.
```{r}
#PERMANOVA
metadata <- data.frame(sample_data(physeq_clr))
results_permanova <- vegan::adonis2(physeq_clr_dist ~ Geo,
                                    data = metadata,
                                    perm = 1000)
results_permanova
```
On voit ici que le regroupement Nord/Sud explique significativement (p < 0,001) 20 % de la variance de la matrice ASV Aitchison. En d’autres termes, les bactéries du Nord et du Sud diffèrent significativement dans leur composition bactérienne. Le test d'ADONIS peut être perturbé par des différences de dispersion (ou de propagation), nous souhaitons donc vérifier cela également.


```{r}
# Testing the assumption of similar multivariate spread among the groups (ie. analogous to variance homogeneity)
anova(vegan::betadisper(physeq_clr_dist, metadata$Geo))
```

Ici, les groupes ont des écarts significativement différents et le résultat de Permanova peut en être affecté, bien que PERMANOVA soit très robuste aux différences de dispersion des groupes. Nous pouvons également vérifier quels taxons contribuent le plus aux différences de communauté en utilisant l'ancienne fonction adonis() et la table ASV des décomptes transformés CLR.
```{r}
#Show coefficients for the top taxa separating the groups

permanova <- vegan::adonis(t(physeq_clr_asv) ~ Geo,
                            data = metadata,
                            permutations = 1000,
                            method = "euclidean")

coef <- coefficients(permanova)["Geo1",]

top.coef <- coef[rev(order(abs(coef)))[1:10]]

par(mar = c(3, 14, 2, 1))

barplot(sort(top.coef),
        horiz = TRUE,
        las = 1,
        main = "Top taxa",
        cex.names = 0.7)
```

adonis()et adonis2()nous permettent d'explorer l'effet de variables catégorielles ou continues .

```{r}
#Permanova on continuous variables
permanova_S <- vegan::adonis2(physeq_clr_dist ~ S,
                              data = metadata,
                              perm = 1000)
permanova_S
```

```{r}
permanova_NH4 <- vegan::adonis2(physeq_clr_dist ~ NH4,
                                data = metadata,
                                perm = 1000)
permanova_NH4
```

```{r}
permanova_PT <- vegan::adonis2(physeq_clr_dist ~ PT,
                               data = metadata,
                               perm = 1000)
permanova_PT
```
Le résultat confirme que la salinité et, dans une moindre mesure, le NH4 et le PT sont des facteurs importants qui façonnent les communautés microbiennes, mais qu'en est-il des autres variables ? Construisons un modèle avec toutes les co-variables.

```{r}
#Inspecting co-variables
permanova_all <- vegan::adonis2(physeq_clr_dist ~ SiOH4 + NO2 + NO3 + NH4 + PO4 + NT + PT + Chla + T + S + Sigma_t,
                                by="margin",
                                data=metadata,
                                perm=1000)

permanova_all
```

Voyons quelles variables explicatives sont corrélées.
```{r}
# inpecting autocorrélation
# compute the correlation matrix
cor_metadadata <- cor(metadata[, 11:21], method = "spearman")

cor_mtest <- function(mat, ...) {
  mat <- as.matrix(mat)
  n <- ncol(mat)
  p_mat <- matrix(NA, n, n)
  diag(p_mat) <- 0
  for (i in 1:(n - 1)) {
    for (j in (i + 1):n) {
      tmp <- cor.test(mat[, i], mat[, j], method = "spearman", ...)
      p_mat[i, j] <- p_mat[j, i] <- tmp$p.value
    }
  }
  colnames(p_mat) <- rownames(p_mat) <- colnames(mat)
  p_mat
}

# matrix of the p-value of the correlation
p_mat <- cor_mtest(metadata[, 11:21])

# Leave blank on no significant coefficient
corrplot::corrplot(cor_metadadata,
                   type = "upper",
                   order = "hclust",
                   p.mat = p_mat,
                   sig.level = 0.05,
                   insig = "blank")
```
On voit que de nombreuses variables explicatives sont corrélées. Supprimons-en quelques-uns. Nous garderons S comme proxy de PO4, Sigma-t, NH4 et NO2. NO3 comme proxy de SiOH4. Chla en tant que mandataire de PT.


```{r}
permanova_cor_pars <- vegan::adonis2(physeq_clr_dist ~ S + NO3 + NT + Chla + T,
                                     by = "margin",
                                     data = metadata,
                                     perm = 1000)
permanova_cor_pars
```
Le modèle PERMANOVA mis à jour est amélioré par rapport à l'original. Nous voyons que la salinité est encore une fois significativement liée à la variable de réponse. Cependant, le modèle avec uniquement la salinité est encore bien meilleur. Le message à retenir est que les véritables relations entre les variables seront masquées si les variables explicatives sont colinéaires. Cela crée des problèmes dans la création de modèles qui entraînent des complications dans l'inférence du modèle. Prendre le temps supplémentaire pour évaluer la colinéarité est une première étape essentielle pour créer des modèles écologiques plus robustes.

Analyse de similarité (ANOSIM):
Il compare les rangs des distances entre les objets de différentes classes avec les rangs des distances des objets au sein des classes. La base de cette approche est similaire à la technique d’ordination NMDS décrite ci-dessus.

```{r}
#ANOSIM
vegan::anosim(physeq_clr_dist, metadata$Geo, permutations = 1000)
```
À l’instar de PERMANOVA, le résultat d’ANOSIM indique un effet significatif de l’origine Nord ou Sud de l’échantillon sur les communautés bactériennes.

Une approche plus formelle du test d'hypothèses peut être réalisée en utilisant une analyse de redondance ou une analyse de correspondance canonique qui utilise directement les informations sur les champs de métadonnées lors de la génération des ordinations et de la réalisation des tests. Ces approches testent directement des hypothèses sur les variables environnementales.

Analyse de gradient direct : 

Analyse redondante (RDA) : 
Excécution du RDA : 
RDA est une méthode combinant régression et analyse en composantes principales (ACP). RDA calcule des axes qui sont des combinaisons linéaires des variables explicatives. En RDA, on peut vraiment dire que les axes expliquent ou modélisent (au sens statistique) la variation de la matrice dépendante.

```{r}
# RDA of the Aitchinson distance
# constrained by all the environmental variables
# contained in metadata
#
# Observe the shortcut formula
spe_rda <- vegan::rda(t(physeq_clr_asv) ~ .,
                      metadata[, 11:21])
head(summary(spe_rda))  # Scaling 2 (default)
```
Les variables environnementales incluses expliquent 70,44 % de la variation de la composition de la communauté bactérienne entre les sites. 29,56 % de la variance est inexpliquée. Cependant, nous verrons que la proportion de variance expliquée est bien plus faible. Le R2 du résumé mesure la force de la relation canonique entre les variables de réponse (matrice Y, ASV) et les variables explicatives (matrice X) en calculant la proportion de la variation de Y expliquée par les variables de X. Cependant, ce R2 est biaisé. Nous calculons un R2 ajusté, qui mesure également la force de la relation entre Y et X, mais applique une correction du R2 pour prendre en compte le nombre de variables explicatives. C’est la statistique qui devrait être rapportée.

```{r}
# Unadjusted R^2 retrieved from the rda object
R2 <- vegan::RsquareAdj(spe_rda)$r.squared
R2
```

```{r}
# Adjusted R^2 retrieved from the rda object
R2adj <- vegan::RsquareAdj(spe_rda)$adj.r.squared
R2adj
```


Tests de signification : 
L'interprétation de l'ordination contrainte doit être précédée d'un test de signification statistique (voir ci-dessous). Comme dans la régression multiple, un résultat non significatif ne doit pas être interprété et doit être écarté.

```{r}
# Global test of the RDA result
anova(spe_rda, step = 1000)
```

```{r}
# Tests of all canonical axes
anova(spe_rda, by = "axis", step = 1000)
```

Ici, nous pouvons voir que votre modèle complet est statistiquement non significatif (p = 0,08), et que tous les axes canoniques résultant de la RDA ne sont pas non plus statistiquement significatifs (p > 0,05). Ce modèle RDA n’est pas interprétable.

Sélection des variables : 
Une approche simple pour identifier la colinéarité entre les variables explicatives consiste à utiliser des facteurs d'inflation de variance (VIF). Les calculs VIF sont simples et facilement compréhensibles ; plus la valeur est élevée, plus la colinéarité est élevée. VIF mesure la proportion dans laquelle la variance d'un coefficient de régression est gonflée en présence d'autres variables explicatives. Les VIF supérieurs à 20 indiquent une forte colinéarité. Idéalement, les VIF supérieurs à 10 devraient au moins être examinés et évités si possible.
```{r}
# Variance inflation factors (VIF)
vegan::vif.cca(spe_rda)
```

Ici, nous effectuerons une sélection avancée sur nos 11 variables environnementales. Pour ce faire, nous pouvons utiliser la fonction ordiR2step() :
```{r}
# Forward selection of explanatory variables using vegan's ordiR2step()
step_forward <- vegan::ordiR2step(vegan::rda(t(physeq_clr_asv) ~ 1,
                                             data = metadata[, 11:21]),
                                  scope = formula(spe_rda),
                                  direction = "forward",
                                  pstep = 1000)
```
Ici, nous ajoutons essentiellement une variable à la fois et la conservons si elle augmente considérablement le R2 ajusté du modèle. La sélection directe nous montre qu'un modèle avec uniquement la salinité a un ajustement R2 plus élevé qu'avec toutes les variables et explique 18,4 % de la variance. Calculons ce RDA le plus parcimonieux et vérifions sa signification.


```{r}
# Parsimonious RDA
spe_rda_pars <- vegan::rda(t(physeq_clr_asv) ~ S, data = metadata[, 11:21])
anova(spe_rda_pars, step = 1000)
```

```{r}
anova(spe_rda_pars, step = 1000, by = "axis")
```

```{r}
R2adj_pars <- vegan::RsquareAdj(spe_rda_pars)$adj.r.squared

# Compare variance inflation factors
vegan::vif.cca(spe_rda)
```

```{r}
vegan::vif.cca(spe_rda_pars)
```
Désormais, le modèle et le premier axe canonique résultant de la RDA sont statistiquement significatifs (p < 0,05). Le VIF de salinité n'est que de 1. Ce modèle RDA est interprétable. Traçons-le.

Tracé RDA : 
```{r}
# Preparation of the data for the plot
#
# View analysis results
ii <- summary(spe_rda_pars)

# Depending on the drawing result
# the drawing data can be enlarged or
# reduced to a certain extent, as follows
sp <- as.data.frame(ii$species[, 1:2]) * 2
sp_top <- sp[order(abs(sp$RDA1), decreasing = TRUE), ][1:6, ]

st <- as.data.frame(ii$sites[, 1:2])
st <- merge(st,
      metadata["Geo"],
      by = "row.names")

yz <- t(as.data.frame(ii$biplot[, 1:2]))
row.names(yz) <- "Salinity"
yz <- as.data.frame(yz)

eigen_values <- format(100 *ii$cont[[1]][2,], digits=4)

#plot
ggplot() +
  geom_point(data = st, size = 4,
             aes(x = RDA1, y = PC1,
                 shape = Geo, fill = Geo)) +
  scale_shape_manual(values = c(21:25)) +
  geom_segment(data = sp_top,
               arrow = arrow(angle = 22.5,
                             length = unit(0.35, "cm"),
                             type = "closed"),
               linetype = 1, size = 0.6, colour = "red",
               aes(x = 0, y = 0, xend = RDA1, yend = PC1)) +
  ggrepel::geom_text_repel(data = sp_top,
                           aes(x = RDA1, y = PC1, label = row.names(sp_top))) +
  geom_segment(data = yz,
               arrow = arrow(angle = 22.5,
                             length = unit(0.35,"cm"),
                             type = "closed"),
               linetype = 1, size = 0.6, colour = "blue",
               aes(x = 0, y = 0, xend = RDA1, yend = PC1)) +
  ggrepel::geom_text_repel(data = yz, aes(RDA1, PC1, label=row.names(yz)))+
  labs(x = paste("RDA 1 (", eigen_values[1], "%)", sep = ""),
       y = paste("PC 1 (", eigen_values[2], "%)", sep = ""))+
  geom_hline(yintercept = 0,linetype = 3,size = 1) + 
  geom_vline(xintercept = 0,linetype = 3,size = 1)+
  guides(shape = guide_legend(title = NULL,
         color = "black"),
         fill = guide_legend(title = NULL))+
  theme_bw() +
  theme(panel.grid = element_blank())
```
L'un des aspects les plus puissants de la RDA est la visualisation simultanée de votre réponse et des variables explicatives (c'est-à-dire les espèces et les variables environnementales). De cette ordination, nous pouvons vraiment dire maintenant que la salinité est le principal facteur environnemental mesuré qui façonne les communautés bactériennes.

Régression multiple sur matrices de dissimilarité (MRM) : 
Nous calculons d’abord la matrice de distance spatiale. Afin de calculer la distance kilométrique entre les points d'échantillonnage à partir de coordonnées géographiques, nous avons utilisé le package SpatialEpi et la fonction latlong2grid() . Ici, vous allez charger le résultat de cette fonction car il y a un conflit avec ce package et le package betapart que nous utilisons après.
```{r}
#library(SpatialEpi)
#ANFcoord <- read.table("Location_coordinates.txt", sep = "\t", row.names = 1, header = T)
#ANF_km <- latlong2grid(ANFcoord[,1:2])
#rownames(ANF_km) <- rownames(ANFcoord)

ANF_km <- readRDS(here::here("course-material-main","data","beta_diversity","spatial_distance.rds"))
ANF_km_dist <- dist(ANF_km)
```

Ensuite, la relation entre la similarité microbienne par paire et la distance spatiale est évaluée en ajustant une fonction exponentielle négative décrivant la diminution de la similarité microbienne avec la distance spatiale.
```{r}
#Calculate and add model to the plot

ANF_decay_exp <- betapart::decay.model(physeq_clr_dist/100,
                                       ANF_km_dist,
                                       y.type="dissim",
                                       model.type="exp",
                                       perm=100)

#Plot Distance decay relationships
plot(ANF_km_dist, physeq_clr_dist/100,
     ylim=c(0, max(physeq_clr_dist/100)),
     xlim=c(0, max(ANF_km_dist)),
     xlab = "Distance (km)", ylab = "Dissimilarity (CLR)")

betapart::plot.decay(ANF_decay_exp, col = "blue",
                     remove.dots = TRUE, add = TRUE)

legend("bottomright",
       paste("exp: (Beta =", round(ANF_decay_exp$second.parameter, 4),
             ", Rsqr =", round(ANF_decay_exp$pseudo.r.squared, 2),
             ", p =", round(ANF_decay_exp$p.value, 2)),
       fill = "blue")
```

```{r}
#Calculate and add model to the plot

ANF_decay_exp <- betapart::decay.model(physeq_clr_dist/100,
                                       ANF_km_dist,
                                       y.type="dissim",
                                       model.type="exp",
                                       perm=100)

#Plot Distance decay relationships
plot(ANF_km_dist, physeq_clr_dist/100,
     ylim=c(0, max(physeq_clr_dist/100)),
     xlim=c(0, max(ANF_km_dist)),
     xlab = "Distance (km)", ylab = "Dissimilarity (CLR)")

betapart::plot.decay(ANF_decay_exp, col = "blue",
                     remove.dots = TRUE, add = TRUE)

legend("bottomright",
       paste("exp: (Beta =", round(ANF_decay_exp$second.parameter, 4),
             ", Rsqr =", round(ANF_decay_exp$pseudo.r.squared, 2),
             ", p =", round(ANF_decay_exp$p.value, 2)),
       fill = "blue")
```

Le modèle exponentiel négatif expliquait de manière significative la décroissance en similarité avec la distance spatiale (p < 0,01). Mais quelle est la contribution de la dispersion et du tri des espèces dans ce schéma ? Découvrons-le en décomposant la variance entre les matrices spatiale et environnementale.

```{r}
#Variance partitioning
#Microbiam matrix (response)
physeq_clr_dist_square <- phyloseq::distance(physeq_clr,
                                             method = "euclidean",
                                             diag = TRUE,
                                             upper = TRUE)

#Spatial matrix (explicative)
ANF_km_dist_square <- dist(ANF_km, diag = TRUE, upper = TRUE)

#environmental matrix (explicative)
envdata <- dist(metadata[,11:21], diag = TRUE, upper = TRUE)
```

```{r}
#Multiple regressions on Matrices (MRM) - attention les colonnes et lignes des matrices doivent correspondrent (pas besoin d'avoir les mêmes noms)

ecodist::MRM(physeq_clr_dist_square ~ envdata + ANF_km_dist_square, nperm=1000) # 0.366
```

```{r}
ecodist::MRM(physeq_clr_dist_square ~ envdata, nperm=1000) # 0.212
```

```{r}
ecodist::MRM(physeq_clr_dist_square ~ ANF_km_dist_square, nperm=1000) # 0.238
```

```{r}
modEvA::varPart(A = 0.212, B = 0.238, AB = 0.366,
                A.name = "Environmental",
                B.name = "Dispersal limitation")
```
En utilisant des matrices de régression multiple sur les distances (MRM), les variables spatiales et environnementales se sont révélées être des prédicteurs significatifs de la diversité bêta et ont expliqué ensemble 36,7 % de la variation de la dissimilarité des communautés microbiennes.

Analyse différentielle d'abondance (DAA):

Analyse discrimiante linéaire Taille de l'effet (LEFse): 
LEFse utilise d'abord le test de classement factoriel non paramétrique de Kruskal-Wallis (KW) pour détecter les caractéristiques présentant une abondance différentielle significative par rapport à la classe d'intérêt ; la cohérence biologique est ensuite étudiée à l'aide d'un ensemble de tests par paires parmi les sous-classes à l'aide du test de somme des rangs de Wilcoxon (non apparié). Dans une dernière étape, LEfSe utilise LDA pour estimer la taille de l'effet de chaque caractéristique différentiellement abondante.
```{r}
#LEFSE
mm_lefse <- microbiomeMarker::run_lefse(physeq, norm = "CPM",
                                        wilcoxon_cutoff = 0.01,
                                        group = "Geo",
                                        taxa_rank = "none",
                                        kw_cutoff = 0.01,
                                        multigrp_strat = TRUE,
                                        lda_cutoff = 4)

mm_lefse_table <- data.frame(mm_lefse@marker_table)
mm_lefse_table
```

```{r}
p_LDAsc <- microbiomeMarker::plot_ef_bar(mm_lefse)
y_labs <- ggplot_build(p_LDAsc)$layout$panel_params[[1]]$y$get_labels()
p_abd <- microbiomeMarker::plot_abundance(mm_lefse, group = "Geo") +
  scale_y_discrete(limits = y_labs)
gridExtra::grid.arrange(p_LDAsc, p_abd, nrow = 1)
```
LEFse identifie 12 biomarqueurs et parmi eux les ASV 7, 11 et 12 que nous avons déjà identifiés précédemment avec d'autres méthodes.

Analyse différentielle des compositions de microbiomes avec correction des biais (ANCO-BC) : 

```{r}
#ancomBC
mm_ancombc <- run_ancombc_patched(
  physeq,
  group = "Geo",
  taxa_rank = "none",
  pvalue_cutoff = 0.001,
  p_adjust = "fdr"
)

mm_ancombc_table <- data.frame(mm_ancombc@marker_table)
mm_ancombc_table
```

```{r}
an_ef <- microbiomeMarker::plot_ef_bar(mm_ancombc)
y_labs <- ggplot_build(an_ef)$layout$panel_params[[1]]$y$get_labels()
an_abd <- microbiomeMarker::plot_abundance(mm_ancombc, group = "Geo") +
  scale_y_discrete(limits = y_labs)
gridExtra::grid.arrange(an_ef, an_abd, nrow = 1)
```
L'ANCOM-BC identifie 10 biomarqueurs et tous en commun avec les résultats de l'analyse LEFse.

Expression différentielle de type ANNOVA (ALDEx2)


```{r}
mm_aldex <- microbiomeMarker::run_aldex(physeq, group = "Geo",
                                        norm = "CPM",
                                        taxa_rank = "none",
                                        p_adjust = "fdr")

mm_aldex_table <- data.frame(mm_aldex@marker_table)
mm_aldex_table
```
ALDEx2 est beaucoup plus strict et identifie un seul biomarqueur, ASV 27 qui a été identifié par les deux autres méthodes DAA. Les autres n’atteignent pas le seuil FDR utilisé ici ; bien qu’ils aient probablement des tailles d’effet « importantes ». Souvent, si j'envisage d'effectuer des tests DA, j'exécuterai plusieurs modèles et me concentrerai sur l'intersection des OTU données par au moins deux méthodes. Ici, il s'agirait du 10 ASV identifié à l'ANCOM-BC.

Il y a une partie qui ne marche pas c'est un probléme de dimensions, je ne sais pas comment résoudre ce problème "incorect number of dimensions"